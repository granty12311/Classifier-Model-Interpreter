{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Model Interpreter Demo\n",
    "\n",
    "A simple tool for interpreting classifier models using SHAP values.\n",
    "\n",
    "## Core Visualizations:\n",
    "- **Model Performance**: Accuracy, AUC, confusion matrix\n",
    "- **Global Feature Importance**: Which features matter most\n",
    "- **Beeswarm Plot**: SHAP value distributions for each feature\n",
    "- **Dependence Plots**: How feature values affect predictions\n",
    "- **Prediction Surface**: 2D/3D views of model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "parent_dir = Path.cwd().parent\n",
    "if str(parent_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from src.core import Interpreter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credit data\n",
    "data_path = Path.cwd().parent / 'data' / 'test_credit_data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "print(f\"Target rate: {df['net_booking'].mean():.1%}\")\n",
    "print(f\"\\nFeatures: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = df.drop(['application_date', 'net_booking'], axis=1).copy()\n",
    "y = df['net_booking'].values\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Test accuracy: {model.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Interpreter\n",
    "\n",
    "Just pass your trained model and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interpreter - SHAP values computed automatically\n",
    "interp = Interpreter(model, X_test, y_test)\n",
    "\n",
    "print(\"Interpreter ready!\")\n",
    "print(f\"Features: {interp.feature_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Model Performance\n",
    "\n",
    "First, let's validate model performance before interpreting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = interp.plot_performance()\n",
    "performance['metrics_summary'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance['confusion_matrix'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance['roc_curve'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Global Feature Importance\n",
    "\n",
    "Which features matter most for predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = interp.plot_global_importance()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Beeswarm Plot\n",
    "\n",
    "Distribution of SHAP values for each feature:\n",
    "- Each dot = one sample\n",
    "- X-axis = SHAP value (impact on prediction)\n",
    "- Color = feature value (red=high, blue=low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = interp.plot_beeswarm()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Dependence Plots\n",
    "\n",
    "How does each feature value affect predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FICO Score\n",
    "fig = interp.plot_dependence('FICO')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTI (Debt-to-Income)\n",
    "fig = interp.plot_dependence('DTI')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LTV (Loan-to-Value)\n",
    "fig = interp.plot_dependence('LTV')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financing Amount\n",
    "fig = interp.plot_dependence('Fin_amt')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Prediction Surface (2D Heatmap)\n",
    "\n",
    "How do two features together affect predicted probability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FICO vs DTI\n",
    "fig = interp.plot_prediction_surface('FICO', 'DTI', n_grid=30)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FICO vs LTV\n",
    "fig = interp.plot_prediction_surface('FICO', 'LTV', n_grid=30)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Prediction Surface (3D)\n",
    "\n",
    "Interactive 3D view of the prediction surface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FICO vs DTI (3D)\n",
    "fig = interp.plot_prediction_surface_3d('FICO', 'DTI', n_grid=25)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FICO vs LTV (3D)\n",
    "fig = interp.plot_prediction_surface_3d('FICO', 'LTV', n_grid=25)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get interpretation summary\n",
    "summary = interp.summary()\n",
    "\n",
    "print(f\"Model: {summary['model_type']}\")\n",
    "print(f\"Samples: {summary['n_samples']:,}\")\n",
    "print(f\"Features: {summary['n_features']}\")\n",
    "print(f\"\\nTop Features:\")\n",
    "for f in summary['top_features'][:5]:\n",
    "    print(f\"  {f['feature']}: {f['importance']:.4f}\")\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  Accuracy: {summary['performance']['accuracy']:.3f}\")\n",
    "print(f\"  AUC: {summary['performance']['auc']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Quick Reference\n",
    "\n",
    "```python\n",
    "from src.core import Interpreter\n",
    "\n",
    "# Initialize\n",
    "interp = Interpreter(model, X_test, y_test)\n",
    "\n",
    "# Core visualizations\n",
    "interp.plot_performance()                    # Model metrics (do this first!)\n",
    "interp.plot_global_importance()              # Feature importance\n",
    "interp.plot_beeswarm()                       # SHAP distributions\n",
    "interp.plot_dependence('feature')            # Single feature effect\n",
    "interp.plot_prediction_surface('f1', 'f2')   # 2D heatmap\n",
    "interp.plot_prediction_surface_3d('f1','f2') # 3D surface\n",
    "interp.summary()                             # Summary dict\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
